{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8552a59",
   "metadata": {},
   "source": [
    "# Before Using this notebook\n",
    "Put a copy of a suitable [HF Auth Token](https://huggingface.co/docs/hub/security-tokens) in a file named `hf_auth` with no new line (to be read by the following code in `edict_functions.py`)\n",
    "```\n",
    "with open('hf_auth', 'r') as f:\n",
    "    auth_token = f.readlines()[0].strip()\n",
    "    \n",
    "```\n",
    "\n",
    "Example file at `./hf_auth`\n",
    "```\n",
    "abc123abc123\n",
    "```\n",
    "\n",
    "\n",
    "Also, run  `conda env create -f environment.yaml`, activate that conda env (`conda activate edict`). Run jupyter with that conda env active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b875361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edict_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cc87b",
   "metadata": {},
   "source": [
    "# Generations\n",
    "\n",
    "To run a novel EDICT generation, use `coupled_stablediffusion(my_prompt)`. This function also takes a steps kwarg that defaults to 50 (can be helpful for more complex generations but rarely needed).\n",
    "\n",
    "EDICT doesn't offer new capabilities for straight-up text-to-image generation, but it's a good sanity check to see how good the generative process we're relying on is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e391d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_EDICT_outputs(im_tuple):\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "    ax0.imshow(im_tuple[0])\n",
    "    ax1.imshow(im_tuple[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968995cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_EDICT_outputs(coupled_stablediffusion('A black bear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_EDICT_outputs(coupled_stablediffusion('A statue of a horse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961cebfe",
   "metadata": {},
   "source": [
    "# Reconstruction\n",
    "\n",
    "Given an image (`x0`), we can invert it into latents `(xt,yt)` and reconstruct it with EDICT passes in different directtions.\n",
    "\n",
    "`run_baseline=True` is the DDIM-C baseline method from our paper, to run DDIM-UC `prompt` should be the empty string `''`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = load_im_into_format_from_path('experiment_images/church.jpg')\n",
    "prompt = 'A church'\n",
    "run_baseline = False\n",
    "\n",
    "latents = coupled_stablediffusion(prompt,\n",
    "                               reverse=True,\n",
    "                                init_image=im,\n",
    "                                run_baseline=run_baseline,\n",
    "                               )\n",
    "if run_baseline:\n",
    "    latents = latents[0]\n",
    "recon = coupled_stablediffusion(prompt,\n",
    "                               reverse=False,\n",
    "                                fixed_starting_latent=latents,\n",
    "                                run_baseline=run_baseline,\n",
    "                               )\n",
    "recon = recon[0]\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1,2)\n",
    "ax0.imshow(im)\n",
    "ax0.set_title(\"Original\")\n",
    "ax1.imshow(recon)\n",
    "ax1.set_title(\"Recon\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e02c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = load_im_into_format_from_path('experiment_images/church.jpg')\n",
    "prompt = 'A church'\n",
    "run_baseline = True # Try vanilla DDIM\n",
    "\n",
    "latents = coupled_stablediffusion(prompt,\n",
    "                               reverse=True,\n",
    "                                init_image=im,\n",
    "                                run_baseline=run_baseline,\n",
    "                               )\n",
    "if run_baseline:\n",
    "    latents = latents[0]\n",
    "recon = coupled_stablediffusion(prompt,\n",
    "                               reverse=False,\n",
    "                                fixed_starting_latent=latents,\n",
    "                                run_baseline=run_baseline,\n",
    "                               )\n",
    "recon = recon[0]\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1,2)\n",
    "ax0.imshow(im)\n",
    "ax0.set_title(\"Original\")\n",
    "ax1.imshow(recon)\n",
    "ax1.set_title(\"Recon\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68185a0f",
   "metadata": {},
   "source": [
    "# Editing\n",
    "\n",
    "\n",
    "We provide a function `EDICT_editing` which accepts an image path, base prompt (original description) and desired edit prompt (target description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = 'experiment_images/imagenet_cake.jpg'\n",
    "base_prompt = 'A cupcake'\n",
    "display(load_im_into_format_from_path(im_path))\n",
    "for edit_prompt in ['An Easter cupcake',\n",
    "                   'A hedgehog cupcake',\n",
    "                   'An England Union Jack cupcake',\n",
    "                   'A Chinese New Year cupcake',\n",
    "                   'A rainbow cupcake']:\n",
    "    print(edit_prompt)\n",
    "    display(EDICT_editing(im_path,\n",
    "              base_prompt,\n",
    "              edit_prompt)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d148c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = 'experiment_images/imagenet_camel.jpg'\n",
    "display(load_im_into_format_from_path(im_path))\n",
    "EDICT_editing(im_path,\n",
    "              'Camel by a fence with a sign',\n",
    "              'Camel by a fence',\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9538e3",
   "metadata": {},
   "source": [
    "Functionality to re-create the dog image edits from our paper (Figures 1 and S16-22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    im_path = f'experiment_images/imagenet_dog_{i}.jpg'\n",
    "    base_prompt = 'A dog' # poodle, dalmatian, lab, german shepherd\n",
    "    print(\"Original\")\n",
    "    display(load_im_into_format_from_path(im_path))\n",
    "    for breed in ['golden retriever', 'chihuahua', 'poodle', 'dalmatian', 'german shepherd', 'husky']:\n",
    "        print(i, breed)\n",
    "        edit_prompt = f'A {breed}'\n",
    "        im0, im0v2 = EDICT_editing(im_path,\n",
    "                  base_prompt,\n",
    "                  edit_prompt,\n",
    "                 run_baseline=False)\n",
    "        display(im0)\n",
    "        display(im0v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd44d99",
   "metadata": {},
   "source": [
    "# Testing on more images\n",
    "\n",
    "We provide many of the images displayed in the paper in the [experiment_images/](experiment_images/) folder.\n",
    "\n",
    "We highly encourage you to test EDICT on in-the-wild images! Editing success varies across images, but generally meaningful edits can be performed. Consider for example [this wikimedia image](https://upload.wikimedia.org/wikipedia/commons/a/a6/Aurora_in_Abisko_near_Tornetr%C3%A4sk.jpg) that was the [Picture of the Day](https://commons.wikimedia.org/wiki/Commons:Picture_of_the_day) while writing this open-source notebook (Dec. 5 2022).\n",
    "\n",
    "First we retrieve the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370e8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! mkdir web_images\n",
    "! wget https://upload.wikimedia.org/wikipedia/commons/a/a6/Aurora_in_Abisko_near_Tornetr%C3%A4sk.jpg -O web_images/aurora.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb123b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Let's check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = 'web_images/aurora.jpg'\n",
    "display(load_im_into_format_from_path(im_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9b8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EDICT_editing(im_path,\n",
    "              'A green aurora over a snowy landscape',\n",
    "              'A polar bear watching a green aurora over a snowy landscape',\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52af5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EDICT_editing(im_path,\n",
    "              'A green aurora over a snowy landscape',\n",
    "              'A red aurora over a snowy landscape',\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDICT_editing(im_path,\n",
    "              'A green aurora over a snowy landscape',\n",
    "              'A couple getting their photo taken in front of a green aurora over a snowy landscape',\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]\n",
    "# Here we notice the scenery changing\n",
    "# Let's see what we can make it change to if we try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4e6f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EDICT_editing(im_path,\n",
    "              'A green aurora over a snowy landscape',\n",
    "              'A green aurora over mountains', # fairly guaranteed this would work from previous edit mistake\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDICT_editing(im_path,\n",
    "              'A green aurora over a snowy landscape',\n",
    "              'A green aurora over a snowy lake',\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDICT_editing(im_path,\n",
    "              'A green aurora over a snowy landscape',\n",
    "              'A green aurora over a forest',\n",
    "             run_baseline=False,\n",
    "             init_image_strength=0.8)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998d39a",
   "metadata": {},
   "source": [
    "# Happy Edi(c)ting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test-env] *",
   "language": "python",
   "name": "conda-env-test-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
